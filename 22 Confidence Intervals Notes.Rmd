---
title: "Confidence Intervals Notes"
author:
- Lt Col Ken Horton
- Professor Bradley Warner
date: "`r format(Sys.time(), '%d %B, %Y')`"
header-includes:
   - \usepackage{multirow}
   - \usepackage{multicol}
output: 
  pdf_document:
    fig_height: 3
    fig_width: 5
  html_document:
    fig_height: 3
    fig_width: 5
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.align='center')
knitr::opts_chunk$set(out.width = "75%")
library(knitr)
library(mosaic)
library(tidyverse)
```

\newcommand{\E}{\mbox{E}}
\newcommand{\Var}{\mbox{Var}}
\newcommand{\Cov}{\mbox{Cov}}
\newcommand{\Prob}{\mbox{P}}
\newcommand{\diff}{\,\mathrm{d}}


## Objectives

# Objectives

1) Define the term confidence interval. 

2) Using asymptotic methods, obtain and interpret a confidence interval for an unknown parameter, based on a random sample. 

3) Describe the relationships between confidence intervals, confidence level, and sample size. 


## confidence interval

A point estimate provides a single plausible value for a parameter. However, a point estimate is rarely perfect; usually there is some error in the estimate. In addition to supplying a point estimate of a parameter, a next logical step would be to provide a plausible **range of values** for the parameter.


### Capturing the population parameter 

A plausible range of values for the population parameter is called a **confidence interval**. Using only a point estimate is like fishing in a murky lake with a spear, and using a confidence interval is like fishing with a net. We can throw a spear where we saw a fish, but we will probably miss. On the other hand, if we toss a net in that area, we have a good chance of catching the fish.

If we report a point estimate, we probably will not hit the exact population parameter. On the other hand, if we report a range of plausible values -- a confidence interval -- we have a good shot at capturing the parameter.

>**Exercise**:
If we want to be very certain we capture the population parameter, should we use a wider interval or a smaller interval?^[If we want to be more certain we will capture the fish, we might use a wider net. Likewise, we use a wider confidence interval if we want to be more certain that we capture the parameter.]


### Constructing a confidence interval  

A point estimate is our best guess for the value of the parameter, so it makes sense to build the confidence interval around that value. The standard error, which is a measure of the uncertainty associated with the point estimate, provides a guide for how large we should make the confidence interval.

Generally, what you should know about building confidence intervals is laid out in the following steps:

1. Identify the parameter you would like to estimate (for example, $\mu$). 

2. Identify a good estimate for that parameter (sample mean, $\bar{X}$). 

3. Determine the distribution of your estimate or a function of your estimate. This tells us where our estimate *should* be if we knew the value of our parameter. (According to the central limit theorem, ${\bar{X}-\mu\over\sigma/\sqrt{n}}\sim \textsf{Norm}(0,1)$ and ${\bar{X}-\mu\over S/\sqrt{n}}\sim \textsf{t}(n-1)$). 

4. Use this distribution to obtain a range of feasible values (confidence interval) for the parameter. (For $\mu$, we can solve for $\mu$ to find a reasonable range). 

> Constructing a 95\% confidence interval for the mean
When the sampling distribution of a point estimate can reasonably be modeled as normal, the point estimate we observe will be within 1.96 standard errors of the true value of interest about 95\% of the time. Thus, a **95\% confidence interval** for such a point estimate can be constructed:  

$$ \hat{\theta} \pm\ 1.96 \times SE_{\hat{\theta}}$$

We can be **95\% confident** this interval captures the true value.

>**Exercise**:  
Compute the area between -1.96 and 1.96 for a normal distribution with mean 0 and standard deviation 1.  

```{r}
pnorm(1.96)-pnorm(-1.96)
```

In mathematical terms, the derivation of this confidence is as follows:

Let $X_1,X_2,...,X_n$ be an iid sequence of random variables, each with mean $\mu$ and standard deviation $\sigma$. The central limit theorem tells us that
$$
{\bar{X}-\mu\over \sigma/\sqrt{n}}\overset{approx}{\sim}\textsf{Norm}(0,1)
$$

Let $0\leq \alpha \leq 1$ with the confidence level being $1-\alpha$, yes $\alpha$ is the same as the significance level in hypothesis testing.. Then,
$$
\Prob\left(-z_{\alpha/2}\leq {\bar{X}-\mu\over \sigma/\sqrt{n}} \leq z_{\alpha/2}\right)=1-\alpha
$$

where $z_{\alpha/2}$ is such that $\Prob(Z\geq z_{\alpha/2})=\alpha/2$, where $Z\sim \textsf{Norm}(0,1)$. A picture would help:

```{r echo=F}
curve(dnorm(x),from=-3.5,to=3.5,xaxt="n",xlab="",ylab="f")
polygon(c(-1.5,seq(-1.5,1.5,0.01),1.5),c(0,dnorm(seq(-1.5,1.5,0.01)),0),density=15)
text(-1.55,0.35,expression(paste("Prob=1-",alpha,sep="")))
arrows(-1.5,0.32,-0.8,0.25,length=0.1)
axis(1,at=c(-1.5,1.5),labels=c(expression(paste("-z_",alpha,"/2",sep="")),expression(paste("z_",alpha,"/2",sep=""))))
text(-3,0.08,expression(paste("Prob=",alpha,"/2",sep="")))
arrows(-3,0.06,-2.25,0.02,length=0.1)
text(3,0.08,expression(paste("Prob=",alpha,"/2",sep="")))
arrows(3,0.06,2.25,0.02,length=0.1)
```

So, I know that $(1-\alpha)*100\%$ of the time, ${\bar{X}-\mu\over \sigma/\sqrt{n}}$ will be between $-z_{\alpha/2}$ and $z_{\alpha/2}$. 

By rearranging the expression above and solving for $\mu$, we get:
$$
\Prob\left(\bar{X}-z_{\alpha/2}{\sigma\over\sqrt{n}}\leq \mu \leq \bar{X}+z_{\alpha/2}{\sigma\over\sqrt{n}}\right)=1-\alpha
$$

Be careful with the interpretation of this expression. As a reminder $\bar{X}$ is the random variable here. The population mean, $\mu$, is NOT a variable. It is an unknown parameter. Thus, the above expression is NOT a probabilistic statement about $\mu$, but rather about $\bar{X}$. 

Nonetheless, the above expression gives us a nice interval for "reasonable" values of $\mu$ given a particular sample. 

A $(1-\alpha)*100\%$ *confidence interval for the mean* is given by:
$$
\mu\in\left(\bar{X}\pm z_{\alpha/2}{\sigma\over\sqrt{n}}\right)
$$

In most applications, the most common value of $\alpha$ is 0.05. In that case, to construct a 95% confidence interval, we would need to find $z_{0.025}$ which can be found quickly with `qnorm()`:
```{r}
qnorm(1-0.05/2)
```

#### Unknown Variance

When inferring about the population mean, we usually will have to estimate the underlying standard deviation as well. This introduces an extra level of uncertainty. We found that while ${\bar{X}-\mu\over\sigma/\sqrt{n}}$ has an approximate normal distribution, ${\bar{X}-\mu\over S/\sqrt{n}}$ follows the $t$-distribution with $n-1$ degrees of freedom. 

Thus, when $\sigma$ is unknown, a $(1-\alpha)*100\%$ confidence interval for the mean is given by: 
$$
\mu\in\left(\bar{X}\pm t_{\alpha/2,n-1}{s\over\sqrt{n}}\right)
$$

Similar to the case above, $t_{\alpha/2,n-1}$ can be found using the `qt()` function in `R`. 


### Body Temperature Example  

>*Example*:  
Find a 95% confidence interval for the body temperature data from last lesson.

```{r echo=FALSE,message=FALSE,warning=FALSE}
temperature <- read_csv("data/temperature.csv")
```

We need the mean, standard deviation, and sample size from this data. The following `R` calculates the confidence interval, make sure you can follow the code.

```{r}
temperature %>%
  favstats(~temperature,data=.) %>%
  select(mean,sd,n) %>%
  summarise(lower_bound=mean-qt(0.975,129)*sd/sqrt(n),upper_bound=mean+qt(0.975,129)*sd/sqrt(n))
```

The 95% confidence interval for $\mu$ is $(98.12,98.38)$. I am 95% *confident* that $\mu$, the average human body temperature, is in this interval. Also, we could say that 95% of similarly constructed intervals will contain the true mean, $\mu$. 

Remember that is the hypothesis test, the null hypothesis was $H_0$:] The average body temperature is 98.6 $\mu = 98.6$. This value is not in the interval, so we could reject the null hypothesis with this confidence interval.

We could also use ` `R` to find the confidence interval.

```{r}
t_test(~temperature,data=temperature)
```

Or if you just want the interval:

```{r}
confint(t_test(~temperature,data=temperature))
```

### One-sided Intervals

If you remember the hypothesis test for temperature in the central limit theorem lesson, you may be crying foul. That was a one-sided hypothesis test and we just conducted a two-sided test. So far, we have discussed only "two-sided" intervals. These intervals have an upper and lower bound. Typically, $\alpha$ is apportioned equally between the two tails. (Thus, we look for $Z_{\alpha/2}$.) 

In "one-sided" intervals, we only bound the interval on one side. We construct one-sided intervals when we are concerned with whether a parameter exceeds some threshold. Building a one-sided interval is similar to building two-sided intervals, except rather than dividing $\alpha$ into two, you simply apportion all of $\alpha$ to the relevant side. The difficult part is to determine if I need an upper bound or lower bound.

For the body temperature study, the alternative hypothesis was that the mean was less than 98.6. In our confidence interval, we want to find the largest value the mean could be and thus we want the upper bound. Repeating the analysis with this in mind.

```{r}
temperature %>%
  favstats(~temperature,data=.) %>%
  select(mean,sd,n) %>%
  summarise(upper_bound=mean+qt(0.95,129)*sd/sqrt(n))
```

```{r}
confint(t_test(~temperature,data=temperature,alternative="less"))
```

Notice that upper bound is smaller since all 0.05 is going into the right tail.


## Confidence intervals in practice
In Section~\ref{basicExampleOfStentsAndStrokes} we encountered an experiment that examined whether implanting a stent in the brain of a patient at risk for a stroke helps reduce the risk of a stroke. The results from the first 30 days of this study, which included 451 patients, are summarized in Table~\ref{stentStudyResultsCIsection}. These results are surprising! The point estimate suggests that patients who received stents may have a \emph{higher} risk of stroke: $p_{trmt} - p_{ctrl} = 0.090$.

\begin{table}[h]
\centering
\begin{tabular}{l cc c}
  \hline
	& 	stroke 	& no event & Total \\
  \hline
treatment 	& 33		& 191	& 224 \\
control 	& 13		& 214	& 227 \\
  \hline
Total		& 46		& 405	& 451 \\
  \hline
\end{tabular}
\caption{Descriptive statistics for 30-day results for the stent study.}
\label{stentStudyResultsCIsection}
\end{table}

\textA{\pagebreak}

\begin{example}{Consider the stent study and results. The conditions necessary to ensure the point estimate $p_{trmt} - p_{ctrl} = 0.090$ is nearly normal have been verified for you, and the estimate's standard error is $SE = 0.028$. Construct a 95\% confidence interval for the change in 30-day stroke rates from usage of the stent.}
\label{stentStroke95CI_CIsection}
The conditions for applying the normal model have already been verified, so we can proceed to the construction of the confidence interval:
\begin{align*}
\text{point estimate}\ \pm\ 1.96 \times SE \quad \rightarrow \quad
0.090\ \pm\ 1.96 \times 0.028 \quad \rightarrow \quad
(0.035, 0.145)
\end{align*}
We are 95\% confident that implanting a stent in a stroke patient's brain increased the risk of stroke within 30 days by a rate of 0.035 to 0.145. This confidence interval can also be used in a way analogous to a hypothesis test: since the interval does not contain 0, it means the data provide statistically significant evidence that the stent used in the study \emph{increases} the risk of stroke, contrary to what researchers had expected before this study was published!
\end{example}

As with hypothesis tests, confidence intervals are imperfect. About 1-in-20 properly constructed 95\% confidence intervals will fail to capture the parameter of interest. Figure~\ref{95PercentConfidenceInterval} shows 25 confidence intervals for a proportion that were constructed from simulations where the true proportion was $p = 0.3$. However, 1 of these 25 confidence intervals happened not to include the true value.

\begin{figure}[hht]
   \centering
   \includegraphics[width=0.9\textwidth]{02/figures/95PercentConfidenceInterval/95PercentConfidenceInterval}
   \caption{Twenty-five samples of size $n=300$ were simulated when $p = 0.30$. For each sample, a confidence interval was created to try to capture the true proportion $p$. However,~1~of these~25 intervals did not capture $p = 0.30$.}
   \label{95PercentConfidenceInterval}
\end{figure}

\begin{exercise}
In Figure~\ref{95PercentConfidenceInterval}, one interval does not contain the true proportion, $p = 0.3$. Does this imply that there was a problem with the simulations run?\footnote{No. Just as some observations occur more than 1.96 standard deviations from the mean, some point estimates will be more than 1.96 standard errors from the parameter. A confidence interval only provides a plausible range of values for a parameter. While we might say other values are implausible based on the data, this does not mean they are impossible.}
\end{exercise}


\subsection{Changing the confidence level}
\label{changingTheConfidenceLevelSection}

\index{confidence interval!confidence level|(}

Suppose we want to consider confidence intervals where the confidence level is somewhat higher than 95\%: perhaps we would like a confidence level of 99\%. Think back to the analogy about trying to catch a fish: if we want to be more sure that we will catch the fish, we should use a wider net. To create a 99\% confidence level, we must also widen our 95\% interval. On the other hand, if we want an interval with lower confidence, such as 90\%, we could make our original 95\% interval slightly slimmer.

The 95\% confidence interval structure provides guidance in how to make intervals with new confidence levels. Below is a general 95\% confidence interval for a point estimate that comes from a nearly normal distribution:
\begin{eqnarray}
\text{point estimate}\ \pm\ 1.96\times SE
\end{eqnarray}
There are three components to this interval: the point estimate, ``1.96'', and the standard error. The choice of $1.96\times SE$ was based on capturing 95\% of the data since the estimate is within 1.96 standard errors of the true value about 95\% of the time. The choice of 1.96 corresponds to a 95\% confidence level. 

\begin{exercise} \label{leadInForMakingA99PercentCIExercise}
If $X$ is a normally distributed random variable, how often will $X$ be within 2.58 standard deviations of the mean?\footnote{This is equivalent to asking how often the $Z$ score will be larger than -2.58 but less than 2.58. (For a picture, see Figure~\ref{choosingZForCI}.) To determine this probability, look up -2.58 and 2.58 in the normal probability table (0.0049 and 0.9951). Thus, there is a $0.9951-0.0049 \approx 0.99$ probability that the unobserved random variable $X$ will be within 2.58 standard deviations of the mean.}
\end{exercise}

To create a 99\% confidence interval, change 1.96 in the 95\% confidence interval formula to be $2.58$. Guided Practice~\ref{leadInForMakingA99PercentCIExercise} highlights that 99\% of the time a normal random variable will be within 2.58 standard deviations of its mean. This approach -- using the Z scores in the normal model to compute confidence levels -- is appropriate when the point estimate is associated with a normal distribution and we can properly compute the standard error. Thus, the formula for a 99\% confidence interval is
\begin{eqnarray}
\text{point estimate}\ \pm\ 2.58\times SE
\label{99PercCIForMean}
\label{99PercCIForNormalPointEstimate}
\end{eqnarray}
%\Comment{I don't know where the equation number above gets referenced. Might drop the equation number.}

\begin{figure}[ht]
\centering
\includegraphics[width=\textwidth]{02/figures/choosingZForCI/choosingZForCI}
\caption{The area between -$z^{\star}$ and $z^{\star}$ increases as $|z^{\star}|$ becomes larger. If the confidence level is 99\%, we choose $z^{\star}$ such that 99\% of the normal curve is between -$z^{\star}$ and $z^{\star}$, which corresponds to 0.5\% in the lower tail and 0.5\% in the upper tail: $z^{\star}=2.58$.}
\label{choosingZForCI}
\index{confidence interval!confidence level|)}
\end{figure}

The normal approximation is crucial to the precision of these confidence intervals. The next two chapters provides detailed discussions about when the normal model can safely be applied to a variety of situations. When the normal model is not a good fit, we will use alternative distributions that better characterize the sampling distribution.

\textA{\pagebreak}

\begin{exercise} \label{find99CIForRun10AgeExercise}
Create a 99\% confidence interval for the impact of the stent on the risk of stroke using the data from Example~\ref{stentStroke95CI_CIsection}. The point estimate is 0.090, and the standard error is $SE = 0.028$. It has been verified for you that the point estimate can reasonably be modeled by a normal distribution.\footnote{Since the necessary conditions for applying the normal model have already been checked for us, we can go straight to the construction of the confidence interval: $\text{point estimate}\ \pm\ 2.58 \times  SE \rightarrow (0.018, 0.162)$. We are 99\% confident that implanting a stent in the brain of a patient who is at risk of stroke increases the risk of stroke within 30 days by a rate of 0.018 to 0.162 (assuming the patients are representative of the population).}
\end{exercise}

\begin{termBox}{\tBoxTitle{Confidence interval for any confidence level}
If the point estimate follows the normal model with standard error $SE$, then a confidence interval for the population parameter is
\begin{eqnarray*}
\text{point estimate}\ \pm\ z^{\star} \times SE
\end{eqnarray*}
where $z^{\star}$ corresponds to the confidence level selected.}
\end{termBox}

Figure~\ref{choosingZForCI} provides a picture of how to identify $z^{\star}$ based on a confidence level. We select $z^{\star}$ so that the area between -$z^{\star}$ and $z^{\star}$ in the normal model corresponds to the confidence level. 

\begin{termBox}{\tBoxTitle{Margin of error}
\label{marginOfErrorTermBox}In a confidence interval, $z^{\star}\times SE$ is called the \term{margin of error}.}
\end{termBox}

\textA{\pagebreak}

\begin{exercise} \label{find90CIForRun10AgeExercise}
In Example~\ref{stentStroke95CI_CIsection} we found that implanting a stent in the brain of a patient at risk for a stroke \emph{increased} the risk of a stroke. The study estimated a 9\% increase in the number of patients who had a stroke, and the standard error of this estimate was about $SE = 2.8\%$. Compute a 90\% confidence interval for the effect.\footnote{We must find $z^{\star}$ such that 90\% of the distribution falls between -$z^{\star}$ and $z^{\star}$ in the standard normal model, $N(\mu=0, \sigma=1)$. We can look up -$z^{\star}$ in the normal probability table by looking for a lower tail of 5\% (the other 5\% is in the upper tail), thus $z^{\star}=1.65$. The 90\% confidence interval can then be computed as $\text{point estimate}\ \pm\ 1.65\times SE \to (4.4\%, 13.6\%)$. (Note: the conditions for normality had earlier been confirmed for us.) That is, we are 90\% confident that implanting a stent in a stroke patient's brain increased the risk of stroke within 30 days by 4.4\% to 13.6\%.}
\end{exercise}

\subsection{Interpreting confidence intervals}
\label{interpretingCIs}

\index{confidence interval!interpretation|(}

A careful eye might have observed the somewhat awkward language used to describe confidence intervals. Correct interpretation:
\begin{quote}
We are XX\% confident that the population parameter is between...
\end{quote}
\emph{Incorrect} language might try to describe the confidence interval as capturing the population parameter with a certain probability. This is one of the most common errors: while it might be useful to think of it as a probability, the confidence level only quantifies how plausible it is that the parameter is in the interval.

Another especially important consideration of confidence intervals is that they \emph{only try to capture the population parameter}. Our intervals say nothing about the confidence of capturing individual observations, a proportion of the observations, or about capturing point estimates. Confidence intervals only attempt to capture population parameters.

\index{confidence interval!interpretation|)}
\index{confidence interval|)}




## File Creation Information 

  * File creation date: `r Sys.Date()`
  * Windows version: `r win.version()`
  * `r R.version.string`
  * `mosaic` package version: `r packageVersion("mosaic")`
  * `tidyverse` package version: `r packageVersion("tidyverse")`
 





