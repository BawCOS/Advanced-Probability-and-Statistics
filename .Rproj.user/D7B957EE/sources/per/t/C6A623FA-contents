---
title: "Continuous Random Variables Notes"
author:
- Lt Col Ken Horton
- Professor Bradley Warner
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  pdf_document:
    fig_height: 3
    fig_width: 5
  html_document:
    fig_height: 3
    fig_width: 5
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.pos='ht')
library(mosaic)
library(tidyverse)
```

\newcommand{\E}{\mbox{E}}
\newcommand{\Var}{\mbox{Var}}
\newcommand{\Cov}{\mbox{Cov}}
\newcommand{\Prob}{\mbox{P}}
\newcommand{\diff}{\,\mathrm{d}}


# Objectives

1) Define the terms probability density function (pdf) and cumulative distribution function (cdf). 

2) Given a continuous random variable, describe probability using the pdf and cdf.

3) Find the mean and variance of a continuous random variable. 


## Continuous Random Variables

In the last lesson, we introduced random variables, and explored discrete random variables. In this lesson, we will move into continuous random variables, their properties, their distribution functions, and how they differ from discrete random variables. 

Recall that a continuous random variable has a domain that is a continuous interval (or possibly a group of intervals). For example, let $Y$ be the random variable corresponding to the height of a randomly selected individual. While our measurement will necessitate "discretizing" height to some degree, technically, height is a continuous random variable since a person could measure 67.3 inches or 67.4 inches or anything in between. 

### Continuous Distribution Functions

So how do we describe the randomness of continuous random variables? In the case of discrete random variables, the probability mass function (pmf) and the cumulative distribution function (cdf) are used to describe randomness. However, recall that the pmf is a function that returns the probability that the random variable takes the inputted value. Due to the nature of continuous random variables, the probability that a continuous random variable takes on any one individual value is technically 0. Thus, a pmf cannot apply to a continuous random variable. 

Rather, we describe the randomness of continuous random variables with the *probability density function* (pdf) and the *cumulative distribution function* (cdf). Note that the cdf has the same interpretation and application as in the discrete case. 

\newpage
### Probability Density Function

Let $X$ be a continuous random variable. The probability density function (pdf) of $X$, given by $f_X(x)$ is a function that describes the behavior of $X$. It is important to note that in the continuous case, $f_X(x)\neq \Prob(X=x)$, as the probability of $X$ taking any one individual value is 0. 

The pdf is a *function*. The input of a pdf is any real number. The output is known as the density. The pdf has three main properties: 

1) $f_X(x)\geq 0$ 

2) $\int_{S_X} f_X(x)\diff x = 1$

3) $\Prob(X\in A)=\int_{x\in A} f_X(x)\diff x$

Properties 2) and 3) imply that the area underneath a pdf represents probability.

### Cumulative Distribution Function

The cumulative distribution function (cdf) of a continuous random variable has the same interpretation as it does for a discrete random variable. It is a *function*. The input of a cdf is any real number, and the output is the probability that the random variable takes a value less than or equal to the inputted value. It is denoted as $F$ and is given by:
$$
F_X(x)=\Prob(X\leq x)=\int_{-\infty}^x f_x(t) \diff t
$$

> *Example*:  
Let $X$ be a continuous random variable with $f_X(x)=2x$ where $0 \leq x \leq 1$. Verify that $f$ is a valid pdf. Find the cdf of $X$. Also, find the following probabilities: $\Prob(X<0.5)$, $\Prob(X>0.5)$, and $\Prob(0.1\leq X < 0.75)$. Finally, find the median of $X$. 

To verify that $f$ is a valid pdf, we simply note that $f_X(x) \geq 0$ on the range $0 \leq x \leq 1$. Also, we note that $\int_0^1 2x \diff x = x^2\bigg|_0^1 = 1$. 

Using `R`, we find

```{r}
integrate(function(x)2*x,0,1)
```


Graphically, the pdf is displayed below:
```{r lesson 9a,fig.align='center',echo=F,fig.cap="pdf of $X$"}
curve(2*x,from=0,to=1,ylab="f(x)",main="pdf of X")
```

\newpage 
The cdf of $X$ is found by 
$$
\int_0^x 2t \diff t = t^2\bigg|_0^x = x^2
$$

So,
$$
F_X(x)=\left\{ \begin{array}{ll} 0, & x<0 \\ x^2, & 0\leq x \leq 1 \\ 1, & x>1 \end{array}\right.
$$

The plot of the cdf of $X$ is shown below: 
```{r lesson9b,fig.align='center',echo=F,fig.cap="cdf of $X$"}
x<-seq(-0.2,1.2,0.001)
y<-pmin(x^2*(x>0),1)
plot(x,y,type="l",ylab="F(x)",main="cdf of X")
```

Probabilities are found either by integrating the pdf or using the cdf:

$\Prob(X < 0.5)=\Prob(X\leq 0.5)=F_X(0.5)=0.5^2=0.25$

```{r lesson9c, fig.height=3,fig.width=4,fig.align='center',echo=F,fig.cap="Probability represented by shaded area"}
x<-seq(0,1,0.001)
y<-2*x
plot(x,y,type="l",ylab="f(x)",main="P(X<0.5)")
polygon(c(0,0.5,0.5),c(0,0,1),density=15,angle=135)
```
$\Prob(X > 0.5) = 1-\Prob(X\leq 0.5)=1-0.25 = 0.75$

```{r lesson9d,fig.align='center',echo=F,fig.cap="Probability represented by shaded area"}
x<-seq(0,1,0.001)
y<-2*x
plot(x,y,type="l",ylab="f(x)",main="P(X>0.5)")
polygon(c(0.5,1,1,0.5),c(0,0,2,1),density=15,angle=135)
```

$\Prob(0.1\leq X < 0.75) = \int_{0.1}^{0.75}2x\diff x = 0.75^2 - 0.1^2 = 0.553$

```{r}
integrate(function(x)2*x,.1,.75)
```


Alternatively, $\Prob(0.1\leq X < 0.75) = F(0.75)-F(0.1)=0.75^2-0.1^2 =0.553$

```{r lesson9e,fig.align='center',echo=F,fig.cap="Probability represented by shaded area"}
x<-seq(0,1,0.001)
y<-2*x
plot(x,y,type="l",ylab="f(x)",main="P(0.1 <= X < 0.75)")
polygon(c(0.1,0.75,0.75,0.1),c(0,0,1.5,0.2),density=15,angle=135)
```

The median of $X$ is the value $x$ such that $\Prob(X\leq x)=0.5$. So we simply solve $x^2=0.5$ for $x$. Thus, the median of $X$ is $\sqrt{0.5}=0.707$. 

Or using `R`

```{r}
uniroot(function(x)x^2-.5,c(0,1))$root
```

### Simulation 

As in the case of the discrete random variable, we can simulate a continuous random variable if we have an inverse for the cdf. The range of the cdf is $[0,1]$, so we generate a random number in this interval and then apply the inverse cdf to obtain a random variable. In a similar manner, for a continuous random variable, we use the following pseudo code:  
1. Generate a random number in the interval $[0,1]$, $U$.  
2. Find the random variable $X$ from $F_{X}^{-1}(U)$.  
In `R` for our example, this looks like the following.

```{r}
sqrt(runif(1))
```

```{r}
results <- do(10000)*sqrt(runif(1))
```

```{r}
inspect(results)
```

```{r}
results %>%
  gf_density(~sqrt,xlab="X")
```


## Moments

As with discrete random variables, moments can be calculated to summarize characteristics such as center and spread. In the discrete case, expectation is found by multiplying each possible value by its associated probability and summing across the domain ($\E(X)=\sum_x x\cdot f_X(x)$). In the continuous case, the domain of $X$ consists of an infinite set of values. From your calculus days, recall that the sum across an infinite domain is represented by an integral. 

Let $g(X)$ be any function of $X$. The expectation of $g(X)$ is found by:
$$
\E(g(X)) = \int_{S_X} g(x)f_X(x)\diff x
$$

### Mean and Variance

Let $X$ be a continuous random variable. The mean of $X$, or $\mu_X$, is simply $\E(X)$. Thus, 
$$
\E(X)=\int_{S_X}x\cdot f_X(x)\diff x
$$

As in the discrete case, the variance of $X$ is the expected squared difference from the mean, or $\E[(X-\mu_X)^2]$. Thus,
$$
\sigma^2_X = \Var(X)=\E[(X-\mu_X)^2]= \int_{S_X} (x-\mu_X)^2\cdot f_X(x) \diff x
$$

Recall Application problem 3 from last lesson. In this problem, you showed that $\Var(X)=\E(X^2)-\E(X)^2$. Thus,
$$
\Var(X)=\E(X^2)-\E(X)^2 = \int_{S_X} x^2\cdot f_X(x)\diff x - \mu_X^2 
$$

> *Example*:  
Consider the random variable $X$ from above. Find the mean and variance of $X$. 
$$
\mu_X= \E(X)=\int_0^1 x\cdot 2x\diff x = \frac{2x^3}{3}\bigg|_0^1 = \frac{2}{3}=0.667
$$

Side note: Since the mean of $X$ is smaller than the median of $X$, we say that $X$ is skewed to the left, or negatively skewed. 

Using `R`.

```{r}
integrate(function(x)x*2*x,0,1)
```

Using our simulation.

```{r}
mean(~sqrt,data=results)
```


$$
\sigma^2_X = \Var(X)= \E(X^2)-\E(X)^2 = \int_0^1 x^2\cdot 2x\diff x - \left(\frac{2}{3}\right)^2 = \frac{2x^4}{4}\bigg|_0^1-\frac{4}{9}=\frac{1}{2}-\frac{4}{9}=\frac{1}{18}=0.056
$$

```{r}
integrate(function(x)x^2*2*x,0,1)$value-(2/3)^2
```

```{r}
var(~sqrt,data=results)*9999/10000
```


And finally, the standard deviation of $X$ is $\sigma_X = \sqrt{\sigma^2_X}=\sqrt{1/18}=0.236$. 
